{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d807d79",
   "metadata": {},
   "source": [
    "# Benchmark avec River\n",
    "\n",
    "## Consigne\n",
    "\n",
    "* Accédez à River, rubrique API Benchmark, et prenez connaissance des méthodes\n",
    "évaluées.\n",
    "* Pré-sélectionnez les méthodes disponibles :\n",
    "* * Régression : toutes les méthodes.\n",
    "* * Classification multi-classes : sélectionnez 3 méthodes et 3 jeux de données.\n",
    "* * Classification binaire : sélectionnez les méthodes dont le temps d’exécution < 1000 secondes.\n",
    "* Exécutez les 3 types de méthodes sur River pour vérifier la compilation et reportez les\n",
    "résultats du benchmark existant.\n",
    "* Présentez une table indiquant en gras les meilleures performances et ajoutez une analyse comparative par dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44695ed",
   "metadata": {},
   "source": [
    "## Approche\n",
    "\n",
    "Pour effectuer ce TP, étant donné le nombres importants d'algorithmes et de datasets, on va faire du multi-threading pour exécuter les benchmarks en parallèle.\n",
    "\n",
    "On va s'inspirer de ce qui est fait dans River pour exécuter les benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b91718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "from config import MODELS, N_CHECKPOINTS, TRACKS\n",
    "from tqdm import tqdm\n",
    "\n",
    "from river import metrics\n",
    "from river.evaluate import Track\n",
    "\n",
    "\n",
    "## Manage logging : make sure only warnings and errors are logged\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODELS[\"Binary classification\"].update(MODELS[\"Multiclass classification\"])\n",
    "details = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1618cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dataset(model_str, no_dataset, track, n_checkpoints=N_CHECKPOINTS):\n",
    "    \"\"\" Run a model on a dataset and return the results.\n",
    "\n",
    "    Args:\n",
    "        model_str (_type_): model name\n",
    "        no_dataset (_type_): dataset index\n",
    "        track (Track) : binary, multiclass or regression in our case\n",
    "\n",
    "    Returns:\n",
    "        results :\n",
    "            step : int\n",
    "            track : str\n",
    "            model : str\n",
    "            dataset : str\n",
    "            ... metric values ...\n",
    "    \"\"\"\n",
    "    if isinstance(track, int):\n",
    "        track = TRACKS[track]\n",
    "    \n",
    "    if isinstance(model_str, str):    \n",
    "        model_name = model_str    \n",
    "        model = MODELS[track.name][model_name].clone()\n",
    "    else:\n",
    "        model_name = model_str.__class__.__name__\n",
    "        model = model_str.clone()\n",
    "    \n",
    "    dataset = track.datasets[no_dataset]\n",
    "    print(f\"Processing {model_str} on {dataset.__class__.__name__}\")\n",
    "\n",
    "    results = []\n",
    "    track = copy.deepcopy(track)\n",
    "    time = 0.0\n",
    "    \n",
    "    # Run the model on the dataset with a progress bar and N_CHECKPOINTS checkpoints\n",
    "    for i in tqdm(\n",
    "        track.run(model, dataset, n_checkpoints=n_checkpoints),\n",
    "        total=n_checkpoints,\n",
    "        desc=f\"{model_str} on {dataset.__class__.__name__}\",\n",
    "    ):\n",
    "        time += i[\"Time\"].total_seconds()\n",
    "        res = {\n",
    "            \"step\": i[\"Step\"],\n",
    "            \"track\": track.name,\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset.__class__.__name__,\n",
    "        }\n",
    "        for k, v in i.items():\n",
    "            if isinstance(v, metrics.base.Metric):\n",
    "                res[k] = v.get()\n",
    "        res[\"Memory in Mb\"] = i[\"Memory\"] / 1024**2\n",
    "        res[\"Time in s\"] = time\n",
    "        results.append(res)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_track(models: list[str], track: Track, n_workers: int = 50, n_checkpoints: int = N_CHECKPOINTS, pickle=True):\n",
    "    \"\"\" Run a track with multiple models in parallel.\n",
    "\n",
    "    Args:\n",
    "        models (list[str]): list of model names\n",
    "        track (Track): track \n",
    "        n_workers (int, optional): number of parallel workers. Defaults to 50.\n",
    "    \"\"\"\n",
    "    if isinstance(track, int):\n",
    "        track = TRACKS[track]\n",
    "        \n",
    "\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=n_workers)\n",
    "    runs = list(itertools.product(models, range(len(track.datasets)), [track], [n_checkpoints]))\n",
    "    results = []\n",
    "\n",
    "    for val in pool.starmap(run_dataset, runs):\n",
    "        results.extend(val)\n",
    "\n",
    "    \n",
    "    csv_name = track.name.replace(\" \", \"_\").lower()\n",
    "    pd.DataFrame(results).to_csv(f\"./{csv_name}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c143433",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Passive-Aggressive Regressor, mode 1 on ChickWeightsProcessing Stochastic Gradient Tree on TrumpApprovalProcessing Linear Regression on ChickWeightsProcessing Linear Regression on TrumpApprovalProcessing Aggregated Mondrian Forest on ChickWeightsProcessing Passive-Aggressive Regressor, mode 1 on TrumpApproval\n",
      "Processing Aggregated Mondrian Forest on TrumpApproval\n",
      "Processing Passive-Aggressive Regressor, mode 2 on TrumpApprovalProcessing k-Nearest Neighbors on TrumpApproval\n",
      "Processing Passive-Aggressive Regressor, mode 2 on ChickWeights\n",
      "Processing Linear Regression with l2 regularization on TrumpApproval\n",
      "Processing Linear Regression with l1 regularization on TrumpApprovalProcessing Hoeffding Tree on TrumpApprovalProcessing Linear Regression with l2 regularization on ChickWeights\n",
      "Processing Linear Regression with l1 regularization on ChickWeightsProcessing Hoeffding Tree on ChickWeightsProcessing k-Nearest Neighbors on ChickWeights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Regression on TrumpApproval:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing Hoeffding Adaptive Tree on ChickWeights\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated Mondrian Forest on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passive-Aggressive Regressor, mode 2 on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors on TrumpApproval:   0%|          | 0/50 [00:00<?, ?it/s] [00:00<?, ?it/s]t/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Adaptive Random Forest on ChickWeights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passive-Aggressive Regressor, mode 1 on TrumpApproval:   0%|          | 0/50 [00:00<?, ?it/s]t/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Adaptive Model Rules on TrumpApprovalProcessing [baseline] Mean predictor on ChickWeightsProcessing Stochastic Gradient Tree on ChickWeights"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Streaming Random Patches on TrumpApproval"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [baseline] Mean predictor on TrumpApprovalProcessing Adaptive Model Rules on ChickWeightsProcessing Streaming Random Patches on ChickWeights\n",
      "Processing Exponentially Weighted Average on ChickWeights"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passive-Aggressive Regressor, mode 1 on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing River MLP on TrumpApprovalProcessing Hoeffding Adaptive Tree on TrumpApproval\n",
      "Processing Adaptive Random Forest on TrumpApprovalProcessing Exponentially Weighted Average on TrumpApproval"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Regression with l1 regularization on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adaptive Random Forest on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adaptive Model Rules on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Streaming Random Patches on TrumpApproval:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing River MLP on ChickWeights"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "River MLP on TrumpApproval:   0%|          | 0/50 [00:00<?, ?it/s]:00<?, ?it/s]]]?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bagging on TrumpApproval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exponentially Weighted Average on ChickWeights:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bagging on TrumpApproval:   0%|          | 0/50 [00:00<?, ?it/s]] [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bagging on ChickWeights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[baseline] Mean predictor on ChickWeights: 53it [00:00, 1183.24it/s]             \n",
      "Linear Regression on TrumpApproval: 51it [00:00, 556.29it/s]              \n",
      "Passive-Aggressive Regressor, mode 1 on ChickWeights: 53it [00:00, 656.19it/s]              \n",
      "Linear Regression on ChickWeights: 53it [00:00, 618.50it/s]              \n",
      "Linear Regression with l2 regularization on TrumpApproval:  92%|█████████▏| 46/50 [00:00<00:00, 452.69it/s]\n",
      "k-Nearest Neighbors on ChickWeights:  24%|██▍       | 12/50 [00:00<00:00, 112.84it/s]                 ]\n",
      "Adaptive Model Rules on ChickWeights:  34%|███▍      | 17/50 [00:00<00:00, 163.22it/s]\n",
      "Stochastic Gradient Tree on ChickWeights:  26%|██▌       | 13/50 [00:00<00:00, 127.68it/s]                 \n",
      "Adaptive Random Forest on ChickWeights:   4%|▍         | 2/50 [00:00<00:02, 16.08it/s]                 \n",
      "Streaming Random Patches on ChickWeights:   4%|▍         | 2/50 [00:00<00:03, 15.65it/s]0it/s]]\n",
      "Streaming Random Patches on TrumpApproval:   2%|▏         | 1/50 [00:00<00:08,  5.86it/s]\n",
      "Adaptive Model Rules on ChickWeights: 53it [00:00, 271.72it/s]                        00<00:00, 211.45it/s]\n",
      "Adaptive Random Forest on ChickWeights:  10%|█         | 5/50 [00:00<00:01, 23.48it/s]                     \n",
      "Stochastic Gradient Tree on TrumpApproval:  24%|██▍       | 12/50 [00:00<00:00, 39.53it/s]             \n",
      "Hoeffding Tree on TrumpApproval: 51it [00:00, 149.80it/s]                        7.34it/s]]\n",
      "Hoeffding Adaptive Tree on ChickWeights: 53it [00:00, 130.72it/s]0:00<00:02, 18.21it/s].29it/s]\n",
      "Hoeffding Adaptive Tree on TrumpApproval: 51it [00:00, 115.24it/s]                        \n",
      "Adaptive Model Rules on TrumpApproval: 51it [00:00, 109.88it/s]                        s]\n",
      "River MLP on ChickWeights: 53it [00:00, 84.68it/s]                        01, 21.49it/s]92it/s]]\n",
      "Stochastic Gradient Tree on ChickWeights: 53it [00:00, 77.19it/s]                        ]\n",
      "River MLP on TrumpApproval: 51it [00:00, 55.83it/s]                        0:01, 19.58it/s]it/s]\n",
      "Bagging on ChickWeights: 53it [00:01, 44.38it/s]                        <00:00, 25.17it/s]s]t/s]\n",
      "Adaptive Random Forest on ChickWeights: 53it [00:01, 34.05it/s]                        s]]s]t/s]\n",
      "Stochastic Gradient Tree on TrumpApproval: 51it [00:01, 28.40it/s]                        ]]\n",
      "Streaming Random Patches on ChickWeights: 53it [00:01, 26.86it/s]                        s]]\n",
      "k-Nearest Neighbors on ChickWeights: 53it [00:02, 24.73it/s]                        .34it/s]\n",
      "Bagging on TrumpApproval: 51it [00:02, 23.90it/s]                        00:01, 14.05it/s]\n",
      "Adaptive Random Forest on TrumpApproval: 51it [00:02, 21.78it/s]                        t/s]\n",
      "Exponentially Weighted Average on ChickWeights: 53it [00:03, 17.36it/s]                        ]\n",
      "Streaming Random Patches on TrumpApproval: 51it [00:03, 13.63it/s]                        4it/s]\n",
      "k-Nearest Neighbors on TrumpApproval: 51it [00:03, 13.33it/s]                         13.07it/s]\n",
      "Aggregated Mondrian Forest on ChickWeights: 53it [00:04, 12.84it/s]7/50 [00:04<00:00, 13.48it/s]\n",
      "Exponentially Weighted Average on TrumpApproval: 51it [00:04, 11.74it/s]                        \n",
      "Aggregated Mondrian Forest on TrumpApproval: 51it [00:07,  7.25it/s]                        \n"
     ]
    }
   ],
   "source": [
    "from river.evaluate import RegressionTrack\n",
    "\n",
    "track = RegressionTrack()\n",
    "\n",
    "details[track.name] = {\"Dataset\": {}, \"Model\": {}}\n",
    "for dataset in track.datasets:\n",
    "    details[track.name][\"Dataset\"][dataset.__class__.__name__] = repr(dataset)\n",
    "for model_name, model in MODELS[track.name].items():\n",
    "    details[track.name][\"Model\"][model_name] = repr(model)\n",
    "with open(\"details.json\", \"w\") as f:\n",
    "    json.dump(details, f, indent=2)\n",
    "run_track(models=MODELS[track.name].keys(), track=track, n_workers=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297f052",
   "metadata": {},
   "source": [
    "## Binary Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcbce807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Logistic regression on BananasProcessing Aggregated Mondrian Forest on PhishingProcessing Aggregated Mondrian Forest on Elec2Processing Aggregated Mondrian Forest on BananasProcessing Aggregated Mondrian Forest on SMTPProcessing Logistic regression on Elec2\n",
      "Processing ALMA on SMTPProcessing Logistic regression on SMTPProcessing sklearn SGDClassifier on Phishing\n",
      "Processing ALMA on Elec2\n",
      "Processing sklearn SGDClassifier on Elec2Processing Logistic regression on Phishing\n",
      "\n",
      "\n",
      "Processing Naive Bayes on Elec2Processing Naive Bayes on Bananas\n",
      "Processing sklearn SGDClassifier on Bananas\n",
      "Processing ALMA on Phishing\n",
      "Processing ALMA on BananasProcessing Naive Bayes on SMTP\n",
      "\n",
      "\n",
      "\n",
      "Processing Naive Bayes on Phishing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic regression on Bananas:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic regression on Elec2:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Hoeffding Tree on Bananas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated Mondrian Forest on Phishing:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated Mondrian Forest on Bananas:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hoeffding Tree on Phishing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALMA on SMTP:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hoeffding Tree on Elec2Processing Hoeffding Tree on SMTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated Mondrian Forest on SMTP:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn SGDClassifier on Elec2:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Streaming Random Patches on Elec2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Naive Bayes on Bananas:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Adaptive Random Forest on BananasProcessing Adaptive Random Forest on Phishing\n",
      "Processing Hoeffding Adaptive Tree on Elec2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn SGDClassifier on Phishing:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hoeffding Adaptive Tree on PhishingProcessing Hoeffding Adaptive Tree on SMTPProcessing Vowpal Wabbit logistic regression on SMTPProcessing Streaming Random Patches on Bananas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn SGDClassifier on Bananas:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hoeffding Adaptive Tree on BananasProcessing Vowpal Wabbit logistic regression on Elec2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic regression on Phishing:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Adaptive Random Forest on Elec2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALMA on Elec2:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Adaptive Random Forest on SMTPProcessing Streaming Random Patches on SMTP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALMA on Bananas:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sklearn SGDClassifier on SMTPProcessing Vowpal Wabbit logistic regression on Phishing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Naive Bayes on Elec2:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing k-Nearest Neighbors on SMTPProcessing ADWIN Bagging on Bananas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Naive Bayes on SMTP:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ADWIN Bagging on Phishing\n",
      "\n",
      "\n",
      "Processing ADWIN Bagging on Elec2Processing k-Nearest Neighbors on Bananas\n",
      "Processing k-Nearest Neighbors on Phishing\n",
      "\n",
      "Processing Streaming Random Patches on Phishing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Naive Bayes on Phishing:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALMA on Phishing:   0%|          | 0/50 [00:00<?, ?it/s]?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k-Nearest Neighbors on Elec2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Tree on Phishing:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AdaBoost on Elec2\n",
      "\n",
      "\n",
      "Processing ADWIN Bagging on SMTP\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Tree on Elec2:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AdaBoost on Bananas\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adaptive Random Forest on Bananas:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on Elec2:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Vowpal Wabbit logistic regression on Bananas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Tree on SMTP:   0%|          | 0/50 [00:00<?, ?it/s]/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on Bananas:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Streaming Random Patches on SMTP:   0%|          | 0/50 [00:00<?, ?it/s]?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors on SMTP:   0%|          | 0/50 [00:00<?, ?it/s]t/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic regression on Phishing: 100%|██████████| 50/50 [00:00<00:00, 257.73it/s] 19.22it/s]/s]using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "using no cacheusing no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss    \n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      " last          counter         weight          label        predict features\n",
      "n.a.     n.a.                1            1.0        unknown         0.0000        7\n",
      "n.a.     n.a.                1            1.0        unknown         0.0000        5\n",
      "1.000000 1.000000            2            2.0         1.0000         0.0000        5\n",
      "0.677699 0.355399            4            4.0         1.0000         0.4038        6\n",
      "n.a.     n.a.                1            1.0        unknown         0.0000        4\n",
      "1.000000 1.000000            2            2.0         1.0000         0.0000        7\n",
      "0.539460 0.078921            4            4.0         1.0000         0.7191        8\n",
      "0.269730 0.000000            8            8.0         1.0000         1.0000        8\n",
      "0.357386 0.037073            8            8.0         1.0000         0.8440        4\n",
      "0.799760 1.329789           16           16.0        -1.0000        -0.6926        8\n",
      "1.005564 1.211368           32           32.0        -1.0000        -0.3486        8\n",
      "1.167017 1.976647           16           16.0         1.0000         0.1856        3\n",
      "1.000000 1.000000            2            2.0        -1.0000         0.0000        4\n",
      "0.564872 0.129744            4            4.0        -1.0000        -0.6398        4\n",
      "1.049177 0.931338           32           32.0         1.0000         0.4276        6\n",
      "0.532437 0.500003            8            8.0        -1.0000        -0.9976        4\n",
      "0.266573 0.000708           16           16.0        -1.0000        -0.9673        4\n",
      "0.133399 0.000226           32           32.0        -1.0000        -1.0000        4\n",
      "0.802608 0.556039   0.066709 0.000019           64           64.0        -1.0000        -1.0000        4\n",
      "        64           64.0        -1.0000        -0.7806        5\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled learners: gd, scorer-identity, count_label\n",
      "Input label = SIMPLE\n",
      "Output pred = SCALAR\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "0.7092771.005534 1.005504           64           64.0        -1.0000        -0.0845        8\n",
      " 0.615946          128          128.0         1.0000         0.1723        4\n",
      "0.6304280.975500 0.945466          128          128.0        -1.0000        -0.1122        9\n",
      " 0.551579          256          256.0        -1.0000        -0.2627        7\n",
      "0.033355 0.000000          128          128.0        -1.0000        -1.0000        4\n",
      "n.a.     n.a.                1            1.0        unknown         0.0000        3\n",
      "1.000000 1.000000            2            2.0        -1.0000         0.0000        3\n",
      "1.000000 1.000000            4            4.0        -1.0000         0.0000        3\n",
      "1.174140 1.348281            8            8.0         1.0000        -0.4753        3\n",
      "1.047782 0.921424           16           16.0        -1.0000        -0.2965        3\n",
      "1.160103 1.272423           32           32.0         1.0000        -0.0131        3\n",
      "0.596943 0.563458          512          512.0         1.0000         0.7390        4\n",
      "0.016679 0.000003          256          256.0        -1.0000        -1.0000        4\n",
      "0.747866 0.520231          256          256.0         1.0000         0.9180        9\n",
      "1.169826 1.179550           64           64.0         1.0000        -0.0509        3\n",
      "1.114838 1.059850          128          128.0        -1.0000         0.0180        3\n",
      "0.479663 0.362383         1024         1024.0         1.0000         1.0000        3\n",
      "0.008340 0.000000          512          512.0        -1.0000        -1.0000        4\n",
      "1.047756 0.980674          256          256.0         1.0000        -0.2773        3\n",
      "0.704031 0.660196          512          512.0        -1.0000         0.0380        9\n",
      "0.004170 0.000000         1024         1024.0        -1.0000        -1.0000        4\n",
      "1.025241 1.002725          512          512.0        -1.0000         0.0960        3\n",
      "0.403277 0.326890         2048         2048.0        -1.0000        -0.8188        7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AdaBoost on Phishing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALMA on Bananas:  24%|██▍       | 12/50 [00:00<00:00, 53.34it/s]50/50 [00:00<00:00, 260.68it/s]\n",
      "Naive Bayes on Bananas:  20%|██        | 10/50 [00:00<00:00, 44.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AdaBoost on SMTP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic regression on Elec2:   2%|▏         | 1/50 [00:00<00:12,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Tree on SMTP:   2%|▏         | 1/50 [00:00<00:14,  3.31it/s]2it/s]it/s]]81it/s]/s]\n",
      "ALMA on SMTP:   2%|▏         | 1/50 [00:00<00:17,  2.88it/s].53it/s]it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bagging on Bananas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALMA on Bananas:  36%|███▌      | 18/50 [00:00<00:00, 49.65it/s]0:08,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn SGDClassifier on Phishing:  16%|█▌        | 8/50 [00:00<00:01, 21.98it/s]2.75it/s]/s]0.002085 0.000000         2048         2048.0        -1.0000        -1.0000        4\n",
      "\n",
      "finished run\n",
      "number of examples = 2500\n",
      "weighted example sum = 2500.000000\n",
      "weighted label sum = -154.000000\n",
      "average loss = 0.385539\n",
      "best constant = -0.123200\n",
      "best constant's loss = 0.984822\n",
      "total feature number = 15652\n",
      "1.006213 0.987185         1024         1024.0         1.0000        -0.1903        3\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 0\n",
      "0.670015 0.635999         1024         1024.0         1.0000         0.7296        9\n",
      "0.994244 0.982274         2048         2048.0        -1.0000        -0.2130        3\n",
      "0.001042 0.000000         4096         4096.0        -1.0000        -1.0000        4\n",
      "k-Nearest Neighbors on Phishing:  14%|█▍        | 7/50 [00:00<00:02, 19.55it/s]0it/s]\n",
      "Logistic regression on Elec2:   4%|▍         | 2/50 [00:00<00:10,  4.77it/s]4it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bagging on Elec2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Naive Bayes on Phishing: 100%|██████████| 50/50 [00:00<00:00, 95.41it/s] 24.29it/s]43.07it/s]\n",
      "sklearn SGDClassifier on Bananas:   8%|▊         | 4/50 [00:00<00:06,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bagging on Phishing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vowpal Wabbit logistic regression on Elec2:   4%|▍         | 2/50 [00:00<00:12,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on SMTP:   2%|▏         | 1/50 [00:00<00:28,  1.70it/s]it/s]s]0.627324 0.584633         2048         2048.0        -1.0000        -0.9190        9\n",
      "0.999660 1.005076         4096         4096.0        -1.0000         0.0237        3\n",
      "Adaptive Random Forest on Phishing:   8%|▊         | 4/50 [00:00<00:08,  5.45it/s].94it/s]/s]0.577826 0.528328         4096         4096.0        -1.0000        -0.5765        9\n",
      "0.000521 0.000000         8192         8192.0        -1.0000        -1.0000        4\n",
      "Vowpal Wabbit logistic regression on Bananas: 100%|██████████| 50/50 [00:01<00:00, 48.22it/s]\n",
      "\n",
      "Adaptive Random Forest on Bananas:   4%|▍         | 2/50 [00:01<00:25,  1.86it/s]0.996027 0.992395         8192         8192.0        -1.0000        -0.1376        3\n",
      "0.568387 0.558947         8192         8192.0        -1.0000        -0.2747        9\n",
      "\n",
      "finished run\n",
      "number of examples = 10600\n",
      "weighted example sum = 10600.000000\n",
      "weighted label sum = -548.000000\n",
      "average loss = 0.992353\n",
      "best constant = -0.103396\n",
      "best constant's loss = 0.989309\n",
      "total feature number = 31800\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 0\n",
      "AdaBoost on Phishing:  20%|██        | 10/50 [00:00<00:04,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bagging on SMTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adaptive Random Forest on Phishing:  12%|█▏        | 6/50 [00:01<00:07,  6.20it/s].02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Leveraging Bagging on Bananas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on Phishing:  74%|███████▍  | 37/50 [00:01<00:00, 29.69it/s]\n",
      "Vowpal Wabbit logistic regression on SMTP:   8%|▊         | 4/50 [00:01<00:14,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Leveraging Bagging on Elec2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on Phishing: 100%|██████████| 50/50 [00:01<00:00, 36.20it/s]it/s]]\n",
      "sklearn SGDClassifier on Bananas:  16%|█▌        | 8/50 [00:01<00:08,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Leveraging Bagging on Phishing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn SGDClassifier on Phishing:  54%|█████▍    | 27/50 [00:01<00:01, 15.93it/s]s]0.000261 0.000000        16384        16384.0        -1.0000        -1.0000        4\n",
      "sklearn SGDClassifier on Phishing:  72%|███████▏  | 36/50 [00:01<00:00, 17.81it/s]]t/s]/s]\n",
      "Hoeffding Adaptive Tree on Bananas:  90%|█████████ | 45/50 [00:01<00:00, 22.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Leveraging Bagging on SMTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Tree on SMTP:  12%|█▏        | 6/50 [00:02<00:16,  2.64it/s]0, 23.01it/s]40it/s]\n",
      "Adaptive Random Forest on Bananas:   8%|▊         | 4/50 [00:02<00:25,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stacking on Bananas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors on Phishing:  36%|███▌      | 18/50 [00:02<00:06,  5.25it/s]s]s]it/s]\n",
      "ADWIN Bagging on Phishing:  16%|█▌        | 8/50 [00:02<00:11,  3.64it/s]05,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stacking on Elec2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn SGDClassifier on Phishing:  92%|█████████▏| 46/50 [00:02<00:00, 16.05it/s]it/s]/s]0.576888 0.585389        16384        16384.0         1.0000         0.2746        9\n",
      "Hoeffding Adaptive Tree on Elec2:  10%|█         | 5/50 [00:02<00:24,  1.86it/s]s]]]93it/s]\n",
      "Leveraging Bagging on Phishing:   6%|▌         | 3/50 [00:01<00:23,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stacking on Phishing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bagging on Phishing:  28%|██▊       | 14/50 [00:02<00:05,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Naive Bayes on Elec2:  14%|█▍        | 7/50 [00:03<00:17,  2.43it/s]9it/s]5.95it/s]s]s]t/s]0.000931 0.001601        32768        32768.0        -1.0000        -1.0000        4\n",
      "Logistic regression on Elec2:  42%|████▏     | 21/50 [00:04<00:04,  6.09it/s] 4.22it/s]t/s]0.560467 0.544046        32768        32768.0         1.0000        -0.1656        9\n",
      "AdaBoost on SMTP:  10%|█         | 5/50 [00:06<01:05,  1.45s/it]/s]24,  1.61it/s] 4.94it/s]\n",
      "ALMA on SMTP:  40%|████      | 20/50 [00:06<00:10,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stacking on SMTP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Streaming Random Patches on Phishing:  38%|███▊      | 19/50 [00:06<00:17,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on SMTP:  30%|███       | 15/50 [00:08<00:23,  1.50it/s]it/s]5it/s]0.600512 0.640557        65536        65536.0         1.0000         0.2733        9\n",
      "0.000529 0.000126        65536        65536.0        -1.0000        -1.0000        4\n",
      "ALMA on SMTP:  54%|█████▍    | 27/50 [00:09<00:07,  2.99it/s]0,  5.29it/s]0:11,  2.53it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Voting on Bananas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AdaBoost on Bananas:  88%|████████▊ | 44/50 [00:09<00:00,  6.04it/s] 1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leveraging Bagging on Bananas:  30%|███       | 15/50 [00:08<00:20,  1.72it/s]4.98it/s]t/s]\n",
      "AdaBoost on Bananas:  94%|█████████▍| 47/50 [00:10<00:00,  5.18it/s]]0:07,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Voting on Elec2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic regression on Elec2:  92%|█████████▏| 46/50 [00:10<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leveraging Bagging on Phishing:  38%|███▊      | 19/50 [00:09<00:11,  2.74it/s]03it/s]it/s]\n",
      "Vowpal Wabbit logistic regression on SMTP:  50%|█████     | 25/50 [00:10<00:08,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Voting on Phishing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Streaming Random Patches on Phishing:  60%|██████    | 30/50 [00:10<00:07,  2.68it/s]1it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Voting on SMTP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vowpal Wabbit logistic regression on SMTP:  52%|█████▏    | 26/50 [00:10<00:07,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bagging on Phishing: 100%|██████████| 50/50 [00:10<00:00,  4.65it/s] 1.67it/s]it/s]s]9it/s]\n",
      "Vowpal Wabbit logistic regression on Elec2:  98%|█████████▊| 49/50 [00:11<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [baseline] Last Class on Bananas"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic regression on Elec2: 51it [00:11,  4.47it/s]                        6,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bagging on Bananas:  74%|███████▍  | 37/50 [00:11<00:03,  3.30it/s]it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [baseline] Last Class on Elec2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated Mondrian Forest on Bananas:  38%|███▊      | 19/50 [00:11<00:22,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adaptive Random Forest on Bananas:  30%|███       | 15/50 [00:11<00:34,  1.01it/s]]s]\n",
      "Vowpal Wabbit logistic regression on Elec2: 100%|██████████| 50/50 [00:11<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [baseline] Last Class on Phishing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Naive Bayes on SMTP:  24%|██▍       | 12/50 [00:11<00:25,  1.47it/s] 6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn SGDClassifier on SMTP:   8%|▊         | 4/50 [00:11<02:08,  2.80s/it]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [baseline] Last Class on SMTP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hoeffding Adaptive Tree on SMTP:  44%|████▍     | 22/50 [00:11<00:16,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[baseline] Last Class on Bananas:  96%|█████████▌| 48/50 [00:00<00:00, 140.25it/s]]\n",
      "Vowpal Wabbit logistic regression on SMTP:  58%|█████▊    | 29/50 [00:11<00:06,  3.00it/s]\n",
      "Hoeffding Tree on SMTP:  70%|███████   | 35/50 [00:11<00:05,  2.80it/s]\n",
      "finished run\n",
      "number of examples = 90624\n",
      "weighted example sum = 90624.000000\n",
      "weighted label sum = -6838.000000\n",
      "average loss = 0.585391\n",
      "best constant = -0.150909\n",
      "best constant's loss = 0.977226\n",
      "total feature number = 813498\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 0\n",
      "[baseline] Last Class on Elec2:   8%|▊         | 4/50 [00:00<00:06,  7.43it/s]/s]t/s]\n",
      "ADWIN Bagging on Bananas: 100%|██████████| 50/50 [00:12<00:00,  3.85it/s]00:04,  3.48it/s]\n",
      "sklearn SGDClassifier on SMTP:  10%|█         | 5/50 [00:13<01:50,  2.47s/it]s]]]].74it/s]0.000804 0.001079       131072       131072.0        -1.0000        -1.0000        4\n",
      "Naive Bayes on Elec2:  74%|███████▍  | 37/50 [00:15<00:05,  2.54it/s]            3.48it/s]\n",
      "ALMA on SMTP:  86%|████████▌ | 43/50 [00:15<00:02,  3.45it/s]00:02, 10.08it/s]s]it/s]\n",
      "Adaptive Random Forest on Elec2:   8%|▊         | 4/50 [00:16<03:04,  4.01s/it]]it/s]it/s]\n",
      "Bagging on Bananas: 100%|██████████| 50/50 [00:16<00:00,  3.00it/s]<00:05,  1.69it/s]it/s]\n",
      "k-Nearest Neighbors on Phishing:  72%|███████▏  | 36/50 [00:17<00:04,  3.24it/s]\n",
      "Logistic regression on SMTP: 51it [00:18,  2.80it/s]                        s]]2it/s]]t/s]\n",
      "Vowpal Wabbit logistic regression on SMTP: 51it [00:18,  2.80it/s]                        \n",
      "Streaming Random Patches on Phishing:  84%|████████▍ | 42/50 [00:18<00:04,  1.66it/s]\n",
      "finished run\n",
      "number of examples = 190312\n",
      "weighted example sum = 190312.000000\n",
      "weighted label sum = -95096.000000\n",
      "average loss = 0.000643\n",
      "best constant = -0.999369\n",
      "best constant's loss = 0.001261\n",
      "total feature number = 761248\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 0\n",
      "[baseline] Last Class on SMTP: 51it [00:06,  7.38it/s]                        05it/s]\n",
      "Streaming Random Patches on Phishing: 100%|██████████| 50/50 [00:20<00:00,  2.43it/s]]\n",
      "Naive Bayes on Elec2: 51it [00:20,  2.44it/s]                          2.58it/s]4it/s]\n",
      "Leveraging Bagging on Phishing: 100%|██████████| 50/50 [00:20<00:00,  2.42it/s]]/it]s]\n",
      "k-Nearest Neighbors on Phishing: 100%|██████████| 50/50 [00:24<00:00,  2.07it/s]]t]\n",
      "Leveraging Bagging on Bananas:  68%|██████▊   | 34/50 [00:24<00:10,  1.50it/s]  it]]t]\n",
      "Voting on Phishing: 100%|██████████| 50/50 [00:18<00:00,  2.65it/s]              it]t]\n",
      "\n",
      "k-Nearest Neighbors on Bananas: 100%|██████████| 50/50 [00:29<00:00,  1.67it/s]15s/it]\n",
      "Leveraging Bagging on Bananas: 100%|██████████| 50/50 [00:33<00:00,  1.50it/s]/it]s]s]\n",
      "Stacking on Phishing: 100%|██████████| 50/50 [00:32<00:00,  1.56it/s]:12,  1.40it/s]s]\n",
      "Naive Bayes on SMTP: 51it [00:35,  1.43it/s]                        0:11,  1.36it/s]s]\n",
      "Adaptive Random Forest on Bananas: 100%|██████████| 50/50 [00:39<00:00,  1.27it/s]s]s]\n",
      "Voting on Bananas: 100%|██████████| 50/50 [00:31<00:00,  1.58it/s].39s/it] 1.67it/s]s]\n",
      "Aggregated Mondrian Forest on Bananas: 100%|██████████| 50/50 [00:41<00:00,  1.21it/s]\n",
      "Streaming Random Patches on Bananas: 100%|██████████| 50/50 [00:45<00:00,  1.10it/s]\n",
      "sklearn SGDClassifier on Elec2: 51it [01:00,  1.19s/it]                        ]it]]\n",
      "Stacking on Bananas: 100%|██████████| 50/50 [01:06<00:00,  1.33s/it]:15,  2.22s/it]]\n",
      "Aggregated Mondrian Forest on SMTP: 51it [01:22,  1.61s/it]                        ]\n",
      "AdaBoost on SMTP: 51it [01:23,  1.64s/it]                          6.54s/it]]s/it]\n",
      "ADWIN Bagging on SMTP: 51it [01:35,  1.86s/it]                        ]78s/it]t]/it]\n",
      "sklearn SGDClassifier on SMTP: 51it [01:37,  1.92s/it]                        ]it]\n",
      "ADWIN Bagging on Elec2: 51it [01:38,  1.93s/it]                        6,  5.69s/it]\n",
      "Bagging on SMTP: 51it [01:41,  1.99s/it]                        t]2,  1.75s/it]]]\n",
      "Adaptive Random Forest on SMTP: 51it [01:53,  2.22s/it]                        t]it]\n",
      "AdaBoost on Elec2: 51it [01:57,  2.30s/it]                         4.24s/it]s/it]it]\n",
      "Adaptive Random Forest on Elec2: 51it [02:12,  2.60s/it]                        ]]t]\n",
      "k-Nearest Neighbors on Elec2: 51it [02:22,  2.79s/it]                        s/it]t]\n",
      "Bagging on Elec2: 51it [02:27,  2.89s/it]                        1:14,  3.74s/it]it]\n",
      "Voting on Elec2: 51it [02:29,  2.94s/it]                        00:53,  3.32s/it]it]\n",
      "k-Nearest Neighbors on SMTP: 51it [03:20,  3.94s/it]                        s/it]]t]\n",
      "Leveraging Bagging on SMTP: 51it [03:20,  3.94s/it]                        2s/it]]\n",
      "Streaming Random Patches on SMTP: 51it [03:28,  4.08s/it]                        ]t]\n",
      "Leveraging Bagging on Elec2: 51it [03:34,  4.21s/it]                        0s/it]t]\n",
      "Voting on SMTP: 51it [03:38,  4.29s/it]                        8<00:54,  4.50s/it]t]\n",
      "Streaming Random Patches on Elec2: 51it [04:33,  5.36s/it]                        t]\n",
      "Stacking on Elec2: 51it [04:31,  5.32s/it]                        \n",
      "Aggregated Mondrian Forest on Elec2: 51it [04:40,  5.50s/it]                        \n",
      "Stacking on SMTP: 51it [05:09,  6.08s/it]                        \n"
     ]
    }
   ],
   "source": [
    "from river.evaluate import BinaryClassificationTrack\n",
    "\n",
    "track = BinaryClassificationTrack()\n",
    "\n",
    "details[track.name] = {\"Dataset\": {}, \"Model\": {}}\n",
    "for dataset in track.datasets:\n",
    "    details[track.name][\"Dataset\"][dataset.__class__.__name__] = repr(dataset)\n",
    "for model_name, model in MODELS[track.name].items():\n",
    "    details[track.name][\"Model\"][model_name] = repr(model)\n",
    "with open(\"details.json\", \"w\") as f:\n",
    "    json.dump(details, f, indent=2)\n",
    "run_track(models=MODELS[track.name].keys(), track=track, n_workers=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e4bcd",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf5915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Streaming Random Patches on ImageSegmentsProcessing Adaptive Random Forest on KeystrokeProcessing Adaptive Random Forest on Insects\n",
      "Processing k-Nearest Neighbors on KeystrokeProcessing Streaming Random Patches on KeystrokeProcessing k-Nearest Neighbors on Insects\n",
      "\n",
      "Processing Streaming Random Patches on InsectsProcessing Adaptive Random Forest on ImageSegments\n",
      "\n",
      "\n",
      "Processing k-Nearest Neighbors on ImageSegments\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Streaming Random Patches on ImageSegments:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adaptive Random Forest on Insects:   0%|          | 0/50 [00:00<?, ?it/s]s]it/s]67it/s]s]\n",
      "\n",
      "\n",
      "Adaptive Random Forest on ImageSegments: 51it [00:03, 13.79it/s]                        ]\n",
      "k-Nearest Neighbors on ImageSegments: 51it [00:06,  7.43it/s]                        it/s]\n",
      "Adaptive Random Forest on Keystroke: 100%|██████████| 50/50 [00:15<00:00,  3.32it/s]4it/s]\n",
      "Streaming Random Patches on ImageSegments: 51it [00:20,  2.46it/s]                        \n",
      "k-Nearest Neighbors on Keystroke:  60%|██████    | 30/50 [00:45<00:29,  1.47s/it]s/it]Process ForkPoolWorker-396:\n",
      "Process ForkPoolWorker-397:\n",
      "Process ForkPoolWorker-394:\n",
      "Process ForkPoolWorker-390:\n",
      "Streaming Random Patches on Keystroke:  34%|███▍      | 17/50 [00:45<01:28,  2.67s/it]Process ForkPoolWorker-375:\n",
      "Process ForkPoolWorker-395:\n",
      "Process ForkPoolWorker-379:\n",
      "Process ForkPoolWorker-357:\n",
      "Process ForkPoolWorker-380:\n",
      "Process ForkPoolWorker-352:\n",
      "Process ForkPoolWorker-385:\n",
      "Process ForkPoolWorker-383:\n",
      "Process ForkPoolWorker-398:\n",
      "Process ForkPoolWorker-378:\n",
      "Process ForkPoolWorker-388:\n",
      "Process ForkPoolWorker-399:\n",
      "Process ForkPoolWorker-387:\n",
      "Process ForkPoolWorker-374:\n",
      "Process ForkPoolWorker-354:\n",
      "Process ForkPoolWorker-353:\n",
      "Process ForkPoolWorker-371:\n",
      "Process ForkPoolWorker-384:\n",
      "Process ForkPoolWorker-400:\n",
      "Process ForkPoolWorker-393:\n",
      "Process ForkPoolWorker-389:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(details, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mrun_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 23\u001b[0m, in \u001b[0;36mrun_track\u001b[0;34m(models, track, n_workers, n_checkpoints, pickle)\u001b[0m\n\u001b[1;32m     20\u001b[0m     runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mproduct(models, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(track\u001b[38;5;241m.\u001b[39mdatasets)), [track], [n_checkpoints]))\n\u001b[1;32m     21\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     24\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(val)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-355:\n",
      "Process ForkPoolWorker-365:\n",
      "Process ForkPoolWorker-368:\n",
      "Process ForkPoolWorker-386:\n",
      "Process ForkPoolWorker-370:\n",
      "Process ForkPoolWorker-376:\n",
      "Process ForkPoolWorker-360:\n",
      "Process ForkPoolWorker-377:\n",
      "Process ForkPoolWorker-382:\n",
      "Process ForkPoolWorker-366:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-351:\n",
      "Process ForkPoolWorker-358:\n",
      "Process ForkPoolWorker-392:\n",
      "Process ForkPoolWorker-372:\n",
      "\n",
      "k-Nearest Neighbors on Keystroke:  60%|██████    | 30/50 [00:45<00:30,  1.51s/it]Process ForkPoolWorker-361:\n",
      "Process ForkPoolWorker-367:\n",
      "Process ForkPoolWorker-391:\n",
      "Process ForkPoolWorker-381:\n",
      "Process ForkPoolWorker-369:\n",
      "Process ForkPoolWorker-364:\n",
      "Process ForkPoolWorker-363:\n",
      "Process ForkPoolWorker-373:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-362:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-359:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-356:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_2350920/1335542233.py\", line 35, in run_dataset\n",
      "    for i in tqdm(\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/evaluate/tracks.py\", line 36, in run\n",
      "    yield from evaluate.iter_progressive_val_score(\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/evaluate/progressive_validation.py\", line 218, in iter_progressive_val_score\n",
      "    yield from _progressive_validation(\n",
      "KeyboardInterrupt\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/evaluate/progressive_validation.py\", line 72, in _progressive_validation\n",
      "    y_pred = pred_func(x, **kwargs)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/base/classifier.py\", line 71, in predict_one\n",
      "    y_pred = self.predict_proba_one(x, **kwargs)\n",
      "  File \"/tmp/ipykernel_2350920/1335542233.py\", line 35, in run_dataset\n",
      "    for i in tqdm(\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/ensemble/streaming_random_patches.py\", line 492, in predict_proba_one\n",
      "    y_proba_temp = model.predict_proba_one(x, **kwargs)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/ensemble/streaming_random_patches.py\", line 588, in predict_proba_one\n",
      "    return self.model.predict_proba_one(x_subset, **kwargs)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/tree/hoeffding_tree_classifier.py\", line 412, in predict_proba_one\n",
      "    proba.update(leaf.prediction(x, tree=self))\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/evaluate/tracks.py\", line 36, in run\n",
      "    yield from evaluate.iter_progressive_val_score(\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/evaluate/progressive_validation.py\", line 218, in iter_progressive_val_score\n",
      "    yield from _progressive_validation(\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/tree/nodes/htc_nodes.py\", line 211, in prediction\n",
      "    return do_naive_bayes_prediction(x, self.stats, self.splitters)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/tree/utils.py\", line 57, in do_naive_bayes_prediction\n",
      "    tmp = obs.cond_proba(x[att_idx], class_index)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/evaluate/progressive_validation.py\", line 90, in _progressive_validation\n",
      "    model.learn_one(x, y, **kwargs)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/tree/splitter/gaussian_splitter.py\", line 54, in cond_proba\n",
      "    return obs(att_val)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/compose/pipeline.py\", line 474, in learn_one\n",
      "    step.learn_one(x=x, y=y)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/proba/gaussian.py\", line 79, in __call__\n",
      "    return math.exp((x - self.mu) ** 2 / (-2 * var)) / math.sqrt(math.tau * var)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/proba/gaussian.py\", line 58, in mu\n",
      "    @property\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/neighbors/knn_classifier.py\", line 129, in learn_one\n",
      "    self._nn.append((x, y))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/neighbors/ann/swinn.py\", line 336, in append\n",
      "    self._safe_node_removal(node.uuid)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/neighbors/ann/swinn.py\", line 197, in _safe_node_removal\n",
      "    neighbors, dists = self._search(self[rn].item, self.graph_k, seed=seed, exclude={rn})\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/neighbors/ann/swinn.py\", line 398, in _search\n",
      "    dist = self.dist_func(item, n.item)\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/neighbors/base.py\", line 32, in __call__\n",
      "    return self.distance_function(a[0], b[0])\n",
      "  File \"/home/smaug/Documents/MASTER/DataStream/TP2/env_benchmark/lib/python3.10/site-packages/river/utils/math.py\", line 166, in minkowski_distance\n",
      "    return sum((abs(a.get(k, 0.0) - b.get(k, 0.0))) ** p for k in {*a.keys(), *b.keys()}) ** (1 / p)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from river import (ensemble, forest, preprocessing, neighbors)\n",
    "\n",
    "from river.evaluate import MultiClassClassificationTrack\n",
    "\n",
    "track = MultiClassClassificationTrack()\n",
    "track_no = 1\n",
    "models = {\"Adaptive Random Forest\": forest.ARFClassifier(seed=42),\n",
    "        \"k-Nearest Neighbors\": preprocessing.StandardScaler() | neighbors.KNNClassifier(),\n",
    "\n",
    "        \"Streaming Random Patches\": ensemble.SRPClassifier()}\n",
    "\n",
    "details[track.name] = {\"Dataset\": {}, \"Model\": {}}\n",
    "for dataset in track.datasets:\n",
    "    details[track.name][\"Dataset\"][dataset.__class__.__name__] = repr(dataset)\n",
    "for model_name, model in MODELS[track.name].items():\n",
    "    details[track.name][\"Model\"][model_name] = repr(model)\n",
    "with open(\"details.json\", \"w\") as f:\n",
    "    json.dump(details, f, indent=2)\n",
    "run_track(models=models.keys(), track=track_no, n_workers=50, pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412019be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Adaptive Random Forest', 'AdaBoost', 'Streaming Random Patches'])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859ac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
